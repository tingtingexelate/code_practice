{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "dat = pd.read_csv('~/phone_data.csv')\n",
    "dat['datetime'] = [datetime.strptime(d,'%d/%m/%y %H:%M') for d in dat['date']]\n",
    "dat['date'] = [datetime.strptime(d,'%d/%m/%y %H:%M').date() for d in dat['date']]\n",
    "#dat.set_index('index', inplace=True)\n",
    "dat.drop(columns='index', inplace=True)\n",
    "dat.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.94599384,  0.01209504],\n",
       "       [ 0.73431335,  0.46891071],\n",
       "       [ 0.45516887,  0.71722762]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.random((2,3)).reshape(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "dat = pd.read_csv('~/phone_data.csv')\n",
    "dat['datetime'] = [ datetime.strptime(d, '%d/%m/%y %H:%M') for d in dat['date']]\n",
    "dat['date']  = [ datetime.strptime(d, '%d/%m/%y %H:%M').date() for d in dat['date']]\n",
    "dat.drop(columns = 'index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = dat.groupby(['date','month']).agg({'duration':'sum'})\n",
    "c.drop(index = 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.sum(axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat[dat.date == datetime.date(2014, 10, 15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "a = dat.pivot_table(index = 'month', columns='network', fill_value= 'duration', aggfunc = 'sum')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### time series chart (key is convert index to datetime)\n",
    "a = dat.groupby(['month','network'])['duration'].sum().unstack()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "a.index = pd.to_datetime(a.index)\n",
    "a.plot(figsize=[10,5])\n",
    "plt.show()\n",
    "\n",
    "# histgram\n",
    "import numpy as np\n",
    "dat['duration'].quantile(np.linspace(0,1,11))\n",
    "\n",
    "%matplotlib inline\n",
    "pd.pivot_table(dat, values='duration', index = 'item',columns='network',aggfunc='mean').plot(kind ='bar')\n",
    "\n",
    "### t-test two sample and one sample\n",
    "dat.groupby('item')['duration'].mean()\n",
    "\n",
    "from scipy import stats\n",
    "a = dat[dat['item'] =='call']['duration']\n",
    "b = dat[dat['item'] =='data']['duration']\n",
    "stats.ttest_ind(a,b)\n",
    "stats.ttest_1samp(a,1000)\n",
    "\n",
    "##### data aggregation\n",
    "# How many rows the dataset\n",
    "len(dat)\n",
    "830\n",
    "# What was the longest phone call / data entry?\n",
    "dat.groupby('item')['duration'].max()\n",
    "# How many seconds of phone calls are recorded in total?\n",
    "\n",
    "dat[dat['item'] =='call'].groupby('month')['duration'].sum()\n",
    "\n",
    "# How many entries are there for each month?\n",
    "dat['month'].value_counts().sort_index()\n",
    "\n",
    "# Number of non-null unique network entries\n",
    "dat['network'].dropna().nunique()\n",
    "\"9\"\n",
    "# Get the first entry for each month\n",
    "dat.sort_values(by = ['month','date']).groupby('month').first()\n",
    "\n",
    "# Get the sum of the durations per month\n",
    "dat.groupby('month')['duration'].sum()\n",
    "# Get the number of dates / entries in each month\n",
    "dat.groupby('month')['date'].nunique()\n",
    "# What is the sum of durations, for calls only, to each network\n",
    "dat[dat['item'] == 'call'].groupby('network')['duration'].sum()\n",
    "# How many calls, sms, and data entries are in each month?\n",
    "dat.groupby(['month','item'])['date'].count()\n",
    "\n",
    "# How many calls, texts, and data are sent per month, split by network_type?\n",
    "dat.groupby(['month','network','item'])['date'].count()\n",
    "# produces Pandas Series\n",
    "#data.groupby('month')['duration'].sum() \n",
    "# Produces Pandas DataFrame\n",
    "#data.groupby('month')[['duration']].sum()\n",
    "\n",
    "#data.groupby('month', as_index=False).agg({\"duration\": \"sum\"})\n",
    "# Group the data frame by month and item and extract a number of stats from each group\n",
    "agg = {'duration':{'duration_min':'min','duration_max':'max'},\n",
    "       'network': 'count',\n",
    "        'network_type':'count'}\n",
    "test = dat.groupby(['month','item']).agg(agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df = dat[['duration','item','network','network_type']]\n",
    "\n",
    "Y=df['item']\n",
    "X=df.drop(columns='item')\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler   \n",
    "#StandardScaler (scale feature) - \n",
    "# vs Normalizer (scale each sample)  - \n",
    "# vs Binalizer (conver continuous data to binary based on a threhold)\n",
    "\n",
    "#from sklearn.preprocessing import Binarizer\n",
    "#binarizer = Binarizer(threshold = 0.7)\n",
    "#binarizer.fit_transform(np.array([0,1,2,3,4])[:,np.newaxis])\n",
    "\n",
    "#from sklearn.preprocessing import Normalizer\n",
    "#scalor = Normalizer()\n",
    "#scalor.fit_transform(np.array([0,1,2,3,4])[:,np.newaxis])\n",
    "\n",
    "#scalor = StandardScaler().fit(X['duration'][:,np.newaxis])\n",
    "#X_scaled = scalor.transform(X['duration'][:,np.newaxis])\n",
    "#X_scaled2 =np.hstack((X_scaled, X.drop(columns ='duration').values))\n",
    "\n",
    "scalor = StandardScaler().fit(X)\n",
    "X_scaled2 = scalor.transform(X)\n",
    "X_scaled2\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X_scaled2,Y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "eval_size = 0.1\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "skf.get_n_splits(X_scaled2,Y)\n",
    "\n",
    "for train_index, test_index in skf.split(X_scaled2,Y):\n",
    "    X_train, X_test = X_scaled2[train_index], X_scaled2[test_index]\n",
    "    Y_train, Y_test = Y.values[train_index], Y.values[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "Ytrain = enc.fit_transform(Y_train)\n",
    "Ytest = enc.fit_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, Y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#display(confusion_matrix(Y_test, Y_pred, labels= np.unique(Y_train)))\n",
    "# much better confusion matrix\n",
    "print(pd.crosstab(Y_test, Y_pred, rownames= ['True'], colnames= ['Predicted']).apply(lambda r: 100.0 * r/r.sum()))\n",
    "print(accuracy_score(Y_test, Y_pred))\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "from sklearn.linear_model improt LinearRegression\n",
    "model = LinearRegression(fit_intercept= True)\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "# model = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#model = RandomForestClassifier(n_estimators = 100, n_jobs=1,min_samples_leaf = 5)\n",
    "# Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain\n",
    "\n",
    "#from sklearn.svm import SVC\n",
    "#model = SVC(kernel = 'linear')\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(model, X_train, Y_train, cv=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5**0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def factorial(m):\n",
    "    f = 1\n",
    "    for i in range(m):\n",
    "        f = f* (i+1)\n",
    "    return f\n",
    "factorial(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(model, X_train, Y_train, cv=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('classic')\n",
    "x = np.linspace(0, 10, 1000)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, np.sin(x), '-b', label='Sine')\n",
    "ax.plot(x, np.cos(x), '--r', label='Cosine')\n",
    "ax.axis('equal')\n",
    "leg = ax.legend();\n",
    "ax.legend(loc='upper left', frameon=False)\n",
    "fig.show()\n",
    "\n",
    "import pandas as pd\n",
    "cities = pd.read_csv('data/california_cities.csv')\n",
    "\n",
    "# Extract the data we're interested in\n",
    "lat, lon = cities['latd'], cities['longd']\n",
    "population, area = cities['population_total'], cities['area_total_km2']\n",
    "\n",
    "# Scatter the points, using size and color but no label\n",
    "plt.scatter(lon, lat, label=None,\n",
    "            c=np.log10(population), cmap='viridis',\n",
    "            s=area, linewidth=0, alpha=0.5)\n",
    "plt.axis(aspect='equal')\n",
    "plt.xlabel('longitude')\n",
    "plt.ylabel('latitude')\n",
    "plt.colorbar(label='log$_{10}$(population)')\n",
    "plt.clim(3, 7)\n",
    "\n",
    "# Here we create a legend:\n",
    "# we'll plot empty lists with the desired size and label\n",
    "for area in [100, 300, 500]:\n",
    "    plt.scatter([], [], c='k', alpha=0.3, s=area,\n",
    "                label=str(area) + ' km$^2$')\n",
    "plt.legend(scatterpoints=1, frameon=False, labelspacing=1, title='City Area')\n",
    "\n",
    "plt.title('California Cities: Area and Population');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, sharex='col', sharey='row')\n",
    "\n",
    "# axes are in a two-dimensional array, indexed by [row, col]\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        ax[i, j].text(0.5, 0.5, str((i, j)),\n",
    "                      fontsize=18, ha='center')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ">>> df = pd.DataFrame(np.random.randn(10,3),\n",
    "...                   columns=['Col1', 'Col2', 'Col3'])\n",
    ">>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',\n",
    "...                      'B', 'B', 'B', 'B', 'B'])\n",
    ">>> df['Y'] = pd.Series(['A', 'B', 'A', 'B', 'A',\n",
    "...                      'B', 'A', 'B', 'A', 'B'])\n",
    ">>> boxplot = df.boxplot(column=['Col1', 'Col2'], by=['X', 'Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "conn = pyodbc.connect(r'Driver={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=C:\\Users\\Ron\\Desktop\\testdb.accdb;')\n",
    "\n",
    "SQL_Query = pd.read_sql_query(\n",
    "'''select\n",
    "product_name,\n",
    "product_price_per_unit,\n",
    "units_ordered,\n",
    "((units_ordered) * (product_price_per_unit)) AS revenue\n",
    "from tracking_sales''', conn)\n",
    "\n",
    "df = pd.DataFrame(SQL_Query, columns=['product_name','product_price_per_unit','units_ordered','revenue'])\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pandas.DataFrame.from_records(\n",
    "        run_query(ctx, qry=qry, output=True),\n",
    "        columns=['non_pc_id', 'unique_cnt', 'country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  cnx = snowflake.connector.connect(\n",
    "           user=uid,\n",
    "           password=pwd,\n",
    "           account=account,\n",
    "         )\n",
    "    cursor = ctx.cursor()\n",
    "    print(qry)\n",
    "    cursor.execute(qry)\n",
    "    outputs = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.randint(0,10,(3,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
